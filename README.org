* Ttl

** What
   
*** Good
The beautiful thing about org-mode is the customizability. 
 - org-agenda
 - org-habit
 - org-capture
 - org-journal
 - org-contacts
 - timetracking
 - tables / spreadsheet
 - org-pomodoro
 - org-wiki
 - org-brain
 - org-present?
 - calendar invites
 - export to html/etc.
 - fold / unfold
 - scheduling with other people
 
Acts as an agenda, outliner, wiki, blog, etc. It's secure because single-user. Easy to backup, etc. The best of all worlds if there is only a single device.

*** Bad
1) Cannot easily capture web data, pictures, video, clips, etc.
2) Not simple/easy to access over mobile. Though there are mobileorg and orgzly. 
3) Collaboration (though will need to think about security model here)
   - Whether through publishing blog, document
   - Allowing sharing / delegation of tasks
   - Comments 

*** How
- Capture
- Schedule the time to do it.

- Goals / things / tasks that want to accomplish
- Countdown the number of days to accomplish 
- Get reminded
- Encouragement from others who have the same goal
- Markdown?
- Sharing / Delegation
- Publish
- Reminder / categorization - groceries, etc based on location
  - Notifications 
    - https://github.com/realtime-framework/WebPushNotifications/blob/master/index.js
    - https://pushcrew.com/pricing/
    - https://gauntface.github.io/simple-push-demo/
    - https://github.com/GoogleChrome/samples/tree/gh-pages/push-messaging-and-notifications
    - https://github.com/web-push-libs/web-push-php
    - https://elixirforum.com/t/what-is-the-simplest-way-to-send-notification-from-elixir-app-to-android-device/6264/4

Object/Item/Task (this is the fundamental unit - could be part of goal or habit)
  - UserId
  - ObjectId
  - GoalId maybe null
  - HabitId maybe null
  - ReferenceId (jira, email, picture, note, outlook, integrations, comments)
  - Attachments
  - Properties (likable, commentable, private, etc)
  - Path - in case there are many subtasks
  - Blob
  - Minimum time needed
  - Time spent
  - Time left
  - State
  - Times deferred

This becomes an adventure in either parsing the document and storing everything as one item. Or having to parse the document itself.

Goals
  - Habit (streak based)
  - Time limit
    - Weekly
    - 40 days (short)
    - 6 months (medium)
    - 1 year (long)
  - Success criteria?
  - Could be suggested
  - Breakdown Items + Time
  - Weekly review
  - Reward
  - Start Date
  - End Date

Interaction
  - Comments
  - Reaction (time, parent, author)

Prioritizer
  - bin-packing based on min-time, deadline, priority
  - Every x-y days
  - Schedule
  - Deadline
  - Priority
  - Prior scheduling that worked and was successful
  - Saves the event and the suggestion

Groups
  - set of users
  - topics
  - interactions

Interaction
  - ObjectId
  - UserId
  - Comments
  - Reaction (time, parent, author)

Journal
  - day
  - rating
  - frequency

Open Times
  - UserId
  - Calendar
  - Scheduling
  - Tags associated with times
  - Enum(Tagged - will schedule with tag, Open)

  - Calendar implementation:
    - user_id + template
    - template:
      - { day, date, time, type={"base", "override"}, tag={"work", "sleep", etc} }
      - {[1-5], nil, [9-17], "base", "work"}
      - {[1-5], nil, [8-830], "base", "commute"}
      - {[1-5], nil, [1630-1730], "base", "commute"}
      - {nil, 2017-07-04, nil, type="override", tag={"offday"}


Tags
  - project (assoc with work)
  - podcast (assoc with any)
  - gardening (assoc with home)
  - woodworking (assoc with home)
  - health (assoc with any)
  - meditation (assoc with home)
  - reading (assoc with any)
  - writing (assoc with any)
  - hiking (assoc with offday)

Context
  - bus
  - home
  - work
  - in transport
  - offday

State:
  - stuck
  - delay
  - 5min
  - done
  - open
  - started

*** Others
https://checkvist.com/checklists/627469-name-your-project-and-press-enter
https://workflowy.com/ -- the most mature app
https://www.moo.do -- really nice Google Apps integration
https://checkvist.com/ -- extremely feature rich
https://github.com/novoid/Memacs
https://turtlapp.com/
http://www.makeuseof.com/tag/lightweight-onenote-evernote-alternatives/
https://github.com/scripting/concord

    
  

** Workflow
*** Sync 
This will send the entire file over and at high load and high users cause issues. Will need a emacs client to update properties. 

- Have things locally.
- Initial sync
- Server parses and adds uuid's
  - Stores in database so can do scheduling, sharing, making lists for other people
  - Re-exports with additional property information
- No conflict resolution between local/remote copies.
  Should have a time-vector on each element though.
  Pull down any changes from server and use them. Sync to server overwrites the uploads/changes.
- This workflow requires an api:
  - Import/export whole documents (this can be used by emacs and/or the web editor)

*** Collaboration
A simple use case is someone making a list for someone else to do. Grocery list, etc. 
When is something allowed to be delegated? What are the viewing permissions? Are there spaces with permissions/groups instead? 
Commenting then can be on objects as a generic comment service. However, how would the comments be fetched? They would have to have the same permissions as the parent. Don't want the comment service to have to call back to the parent service for permissions. The other option is replicating / synchronizing the permissions over the the comment system. Another option is only have trusted systems call the comment system and never have it public.    
*** Capturing
Major issue is capturing images, bookmarks, webpages. 

https://github.com/alphapapa/org-protocol-capture-html has some bookmarklets. 

** DONE MVP1
   CLOSED: [2017-09-01 Fri 17:23]
*** DONE Thoughts on parsing and db schema:
    CLOSED: [2017-08-24 Thu 20:59]
  - Can store the entire file and then the tags/headers in separate tables for scheduling
    - If the agenda is modified on web, item state to done, the file needs to be re-written also. Need to keep both in sync.
  - Represent the entire file as an AST and then store it
    - AST table (how to deal with deleted fragments?)
      - doc | [element_paths, uuid1, uuid2, uuid3]  -> export selects and joins all the elements in the path?
        object | [ uuid, uid, gid, content ]
      - how to represent header levels, planning, property, then all the stuff under the header?
      - [header(level=1, uuid=x, planning, property), section(uuid=x, content), header(level=2, uuid=x, planning, property)
      - how to represent a list with tags and without tags?
        - answer: don't. adds complications for now and no point
      - how to collaborate? have another field with users that have access/edit to it? treat each object as a gco
      - associated with a single object - header, planning, properties, section, timelog
      - timelog should have the logbook and the state transitions? or separate tables?
  #+NAME: DBSCHEMA
  - Database schema

     #mix phx.gen.html Things Document documents user_id:references:accounts_users name:string objects:array:uuid:references_things_objects
     mix phx.gen.html Things Document documents user_id:references:accounts_users name:string objects:array:uuid
   
     mix phx.gen.html Things Object objects document_id:references:things_documents path:array:uuid level:integer title:text content:text blob:binary closed:utc_datetime scheduled:utc_datetime deadline:utc_datetime state:string priority:string version:integer defer_count:integer min_time_needed:integer time_spent:integer time_left:integer permissions:integer

     mix phx.gen.html Things Tag tags user_id:references:accounts_users tag:string

     Maybe add a type column to these and call it a day?
     mix phx.gen.html Things Property properties object_id:references:things_objects key:string value:string
     mix phx.gen.html Things Timelog timelogs object_id:references:things_objects key:string value:string
 
     create many to many table things_objects_tags
     create many to many table things_objects_properties

     A document is an array of objects, a header has properties, tags, logbook associated with it, and section. Could also make it more of a tree-like structure, but we're not trying to edit the document, we're trying to get the main parts to do some scheduling and be able to regenerate it.

     An annoying problem is that we want to be able to refresh a document and also reorder or remove any objects. Possible to have a table of UUID's in the document to guarantee order. Another possibility is a many table with reference to document. If objects moved up and down, we would have to update every object. Same for insertion for new objects in the middle of a file. With an array of uuid's, need to just update the array and take care of fragments later. 


      


    - old notes header is essentially an object, but then what is a section? section will be the content of a header
      what about logbook?

    if we want to get a subtree, we also need to put in the path correctly for the subtree
    or can generate subtree - from the doc uuid's

  - how to get a particular ordered subtree of a document?
    we should have a document with a set of uuid's in an order. we need to select up to the last uuid where level = the level we're at
    CREATE EXTENSION pgcrypto; 
    CREATE TABLE contacts(  id UUID PRIMARY KEY DEFAULT gen_random_uuid(), name TEXT, email TEXT);

    snw=# with x (id_list) as ( values (array['bb8f6873-b2f7-4109-a35f-308930e1d57c', '3ccd8a17-0fac-484c-83ab-feacf88c1812', '2eb23b9f-eb9d-40d0-a46a-24c50aa73173'])) select c.* from contacts c, x where cast(id as text) = any (x.id_list) order by array_position(x.id_list, cast( c.id as text));
    id                  |      name       | email 
    --------------------------------------+-----------------+-------
    bb8f6873-b2f7-4109-a35f-308930e1d57c | Geoff Franks    | geoff
    3ccd8a17-0fac-484c-83ab-feacf88c1812 | Dr Nic Williams | drnic
    2eb23b9f-eb9d-40d0-a46a-24c50aa73173 | Jamie Van Dyke  | jamie

  - ttl_dev=# with x (id_list) as ( values (array['ffce2bd3-a4c4-4ea9-98df-e4ebde4452ee','75c3758c-0af9-4f15-a75a-c66a2fbe0299','f3c99da2-f9ef-45d8
-a59d-c2b606be52d6'])) select o.id, o.title from things_objects o, x where cast(id as text) = any (x.id_list) order by array_position(x.id_list
, cast( o.id as text));  
  - with x (id_list) as (select objects from things_documents) select o.id, o.title from things_objects o, x where id = any (x.id_list) order by array_position(x.id_list, o.id );


*** DONE Thoughts on UI Interface
    CLOSED: [2017-08-24 Thu 20:59]

- If this is for power-users, it has to be able to integrate with org-mode. To import/export out of text mode, there needs to be a UUID for each element.

- If tasks can be shared / commented / etc. each item will have to be independent. Also, inheritance is important here, probably just from the top-level. 
- How would conflict resolution be handled? Not sure how to merge diffs between different versions except to have a time-clock.

- https://org-web.org/ - is a rudimentary org-web parser
- http://appsonthemove.com/blog/2017/05/25/borg/
- http://www.orgzly.com/help#org7fa55de
- https://www.reddit.com/r/emacs/comments/6r5htr/capturing_short_notes_on_the_go_then_sync_to_org/

  
*** DONE import/export to api. 
    CLOSED: [2017-08-19 Sat 22:11]
**** DONE write a parser (not going to do in elisp since may want non-emacs users)
     CLOSED: [2017-08-15 Tue 18:27]
**** DONE create db schema
CLOSED: [2017-08-13 Sun 15:01]
[[DBSCHEMA]]
**** DONE consolidate sections
CLOSED: [2017-08-13 Sun 15:00]
:LOGBOOK:
CLOCK: [2017-08-13 Sun 12:14]--[2017-08-13 Sun 12:39] =>  0:25
CLOCK: [2017-08-13 Sun 11:44]--[2017-08-13 Sun 12:09] =>  0:25
CLOCK: [2017-08-13 Sun 11:14]--[2017-08-13 Sun 11:39] =>  0:25
CLOCK: [2017-08-13 Sun 07:18]--[2017-08-13 Sun 07:44] =>  0:26
CLOCK: [2017-08-13 Sun 06:46]--[2017-08-13 Sun 07:12] =>  0:26
:END:
**** DONE Need to fix the planning parser to grab the dates
CLOSED: [2017-08-13 Sun 15:00]
:LOGBOOK:
CLOCK: [2017-08-13 Sun 12:48]--[2017-08-13 Sun 13:13] =>  0:25
:END:
**** DONE consolidate header (property, planning)
CLOSED: [2017-08-13 Sun 15:00]
**** DONE implement db schema
CLOSED: [2017-08-14 Mon 16:44]
:LOGBOOK:
CLOCK: [2017-08-14 Mon 16:14]--[2017-08-14 Mon 16:39] =>  0:25
CLOCK: [2017-08-14 Mon 15:44]--[2017-08-14 Mon 16:09] =>  0:25
CLOCK: [2017-08-14 Mon 15:09]--[2017-08-14 Mon 15:34] =>  0:25
:END:
**** DONE write to database
     CLOSED: [2017-08-15 Tue 21:48]
:LOGBOOK:
CLOCK: [2017-08-15 Tue 11:13]--[2017-08-15 Tue 11:38] =>  0:25
CLOCK: [2017-08-15 Tue 10:44]--[2017-08-15 Tue 11:09] =>  0:25
CLOCK: [2017-08-15 Tue 10:14]--[2017-08-15 Tue 10:39] =>  0:25
CLOCK: [2017-08-15 Tue 09:44]--[2017-08-15 Tue 10:09] =>  0:25
CLOCK: [2017-08-15 Tue 09:11]--[2017-08-15 Tue 09:36] =>  0:25
CLOCK: [2017-08-14 Mon 19:26]--[2017-08-14 Mon 19:46] =>  0:20
CLOCK: [2017-08-14 Mon 18:57]--[2017-08-14 Mon 19:26] =>  0:29
CLOCK: [2017-08-14 Mon 18:31]--[2017-08-14 Mon 18:56] =>  0:25
CLOCK: [2017-08-14 Mon 18:05]--[2017-08-14 Mon 18:30] =>  0:25
CLOCK: [2017-08-14 Mon 17:13]--[2017-08-14 Mon 17:38] =>  0:25
CLOCK: [2017-08-14 Mon 16:44]--[2017-08-14 Mon 17:10] =>  0:26
:END:
The dates need to be parsed to put into the db
Turns out they are of many variable formats, need to use regexp
The scheduler needs to have a few additional fields in db

After mucking around quite a bit with dates, regret not using a lexer. 
Turns out Ecto casting from naive datetime to datetime was the issue. 

Takes a document, parses it, and can insert all the objects into the database

***** DONE Make it into a function 
      CLOSED: [2017-08-15 Tue 20:06]
      :LOGBOOK:
      CLOCK: [2017-08-15 Tue 19:30]--[2017-08-15 Tue 20:00] =>  0:30
      :END:
***** DONE Make a solid decision on what to do on failed update / version conflict
      CLOSED: [2017-08-15 Tue 21:40]
      :LOGBOOK:
      CLOCK: [2017-08-15 Tue 21:00]--[2017-08-15 Tue 21:38] =>  0:38
      CLOCK: [2017-08-15 Tue 20:13]--[2017-08-15 Tue 20:38] =>  0:25
      :END:
***** DONE Parse and cast the dates
      CLOSED: [2017-08-15 Tue 18:19]
      http://orgmode.org/manual/Timestamps.html#Timestamps

      :LOGBOOK:
      CLOCK: [2017-08-15 Tue 16:55]--[2017-08-15 Tue 18:14] =>  1:19
      CLOCK: [2017-08-15 Tue 16:15]--[2017-08-15 Tue 16:51] =>  0:36
      CLOCK: [2017-08-15 Tue 15:30]--[2017-08-15 Tue 16:11] =>  0:41
      CLOCK: [2017-08-15 Tue 15:04]--[2017-08-15 Tue 15:29] =>  0:25
      CLOCK: [2017-08-15 Tue 13:25]--[2017-08-15 Tue 13:50] =>  0:25
      CLOCK: [2017-08-15 Tue 12:43]--[2017-08-15 Tue 13:25] =>  0:42
      CLOCK: [2017-08-15 Tue 12:16]--[2017-08-15 Tue 12:41] =>  0:25
      CLOCK: [2017-08-15 Tue 11:43]--[2017-08-15 Tue 12:08] =>  0:25
      :END:
***** DONE Or maybe need to do versioning right now?
      CLOSED: [2017-08-15 Tue 18:22]
**** DONE Need to parse the file metadata
     CLOSED: [2017-08-15 Tue 23:18]
      CLOCK: [2017-08-15 Tue 21:45]--[2017-08-15 Tue 23:20] =>  1:40
written to the database as jsonb
http://ehneilsen.net/notebook/orgExamples/org-examples.html#sec-2

**** DONE regenerate file from database - with uuid's
     CLOSED: [2017-08-16 Wed 19:18]
     :LOGBOOK:
     CLOCK: [2017-08-16 Wed 18:45]--[2017-08-16 Wed 19:20] =>  0:35
     CLOCK: [2017-08-16 Wed 18:15]--[2017-08-16 Wed 18:40] =>  0:25
     CLOCK: [2017-08-16 Wed 17:40]--[2017-08-16 Wed 18:15] =>  0:35
     CLOCK: [2017-08-16 Wed 17:10]--[2017-08-16 Wed 17:38] =>  0:28
     CLOCK: [2017-08-16 Wed 16:40]--[2017-08-16 Wed 17:08] =>  0:28
     CLOCK: [2017-08-16 Wed 16:11]--[2017-08-16 Wed 16:36] =>  0:25
     CLOCK: [2017-08-16 Wed 12:03]--[2017-08-16 Wed 12:28] =>  0:25
     CLOCK: [2017-08-16 Wed 11:28]--[2017-08-16 Wed 11:53] =>  0:25
     CLOCK: [2017-08-16 Wed 11:05]--[2017-08-16 Wed 11:20] =>  0:15
     CLOCK: [2017-08-16 Wed 10:36]--[2017-08-16 Wed 11:01] =>  0:25
     CLOCK: [2017-08-16 Wed 08:45]--[2017-08-16 Wed 09:00] =>  0:15
     CLOCK: [2017-08-16 Wed 07:25]--[2017-08-16 Wed 07:43] =>  0:18
     :END:
    - The file uuid goes in the metadata at the top
    - The object metadata goes into properties
    - ttl_dev=# with x (id_list) as (select objects from things_documents) select o.id, o.title from things_objects o, x where id = any (x.id_list) order by array_position(x.id_list, o.id  );
    - ttl_dev=# with x (id_list) as (select objects from things_documents) select o.id, o.title from things_objects o, d.metadata from things_documents d,  x where id = any (x.id_list) order by array_position(x.id_list, o.id  );
    - 
***** DONE adjust the levels for files with no bullets to 0 - this will fix for files with no headline
      CLOSED: [2017-08-16 Wed 07:22]
***** DONE bug with closed planning data not being parsed
      CLOSED: [2017-08-16 Wed 07:43]

**** DONE Bugs - adil file has extra newline at start
     CLOSED: [2017-08-16 Wed 19:18]
**** DONE Properties - parse, store, and write
     CLOSED: [2017-08-16 Wed 22:59]
     :LOGBOOK:
     CLOCK: [2017-08-16 Wed 21:10]--[2017-08-16 Wed 22:57] =>  1:47
     :END: 
**** DONE Add file uuid into regenerate
     CLOSED: [2017-08-16 Wed 23:39]
**** DONE Add version and id into regenerated object 
     CLOSED: [2017-08-17 Thu 00:03]
     :LOGBOOK:
     CLOCK: [2017-08-16 Wed 23:39]--[2017-08-17 Thu 00:03] =>  0:24
     :END:
**** DONE Read file uuid from file to pull objects
     CLOSED: [2017-08-17 Thu 11:38]
     :LOGBOOK:
     CLOCK: [2017-08-17 Thu 10:00]--[2017-08-17 Thu 10:57] =>  0:57
     CLOCK: [2017-08-17 Thu 08:55]--[2017-08-17 Thu 09:20] =>  0:25
     CLOCK: [2017-08-17 Thu 08:05]--[2017-08-17 Thu 08:50] =>  0:45
     :END:
**** DONE Start of file exception
     CLOSED: [2017-08-17 Thu 11:38]
     :LOGBOOK:
     CLOCK: [2017-08-17 Thu 11:04]--[2017-08-17 Thu 11:29] =>  0:25
     :END:
**** DONE Ensure data gets updated on change
     CLOSED: [2017-08-17 Thu 13:05]
     :LOGBOOK:
     CLOCK: [2017-08-17 Thu 12:58]--[2017-08-17 Thu 13:06] =>  0:08
     :END:
      Org-mode won't ever update the version locally. If remote_version > local_version => conflict.
      Conflict resolution will require parsing things locally and replacing them
      Tests:
       - An old object (all db counts same)
       - A new object gets added (db count + 1)
       - the new object gets modified (db count same)

**** DONE make an interval data structure for schedule parsing and bin-packing calendar with contexts / tags
     CLOSED: [2017-08-17 Thu 17:53]
     :LOGBOOK:
     CLOCK: [2017-08-19 Sat 11:12]--[2017-08-19 Sat 11:37] =>  0:25
     CLOCK: [2017-08-19 Sat 10:37]--[2017-08-19 Sat 11:02] =>  0:25
     CLOCK: [2017-08-17 Thu 13:42]--[2017-08-17 Thu 14:07] =>  0:25
     :END:
Time can be tagged with multiple contexts. So an interval of time can be tagged work, etc. 
org-mode also has intervals which need to be stored for scheduled time and repetition. 
      CLOSED: [2016-06-02 Thu 21:22] SCHEDULED: <2016-06-08 Wed 09:00+x>--<2016-06-02 9:00-17:00> DEADLINE: <bla>

The agenda display is not important in this case, the api output will need to be generated anyway. 
Easiest format for a single day would be {start_time, interval_size}. This allows for packing things into whatever interval_size available. 
The end times for org-document generation will need to be calculated.  
For the issue of "scheduled" over multiple days, it will need to become a list. [{start_time1, interval1}, {start_time2, interval2}] and repeat_interval
In the db - not sure how to store this? another jsonb?
Use two arrays - one for start time, the other for interval. 
Other option - just have a planning table. 
select * from objects o, planning p where o.id = p.object_id and p.scheduled > $p1 and p.scheduled < $p2 

UPDATE - just going with start_time, start_interval, date_range

     mix phx.gen.html Things Object objects document_id:references:things_documents path:array:uuid level:integer title:text content:text blob:binary state:string priority:string version:integer defer_count:integer min_time_needed:integer time_spent:integer time_left:integer permissions:integer
     mix phx.gen.html Things Planning planning object_id:references:things_objects repeat_interval:string closed:utc_datetime scheduled:utc_datetime scheduled_date_range:integer scheduled_time_interval:integer deadline:utc_datetime 
     mix phx.gen.html Things Property properties object_id:references:things_objects key:string value:string
     mix phx.gen.html Things Timelog timelogs object_id:references:things_objects key:string value:string

Workflow:
Server sees free time. Sorts by priority + tag matching on time slot + longest first? Need to optimize algorithm based on actual results. 
Yes/no -> deferred -> repeat.  
Or set out a full schedule at night. 
Data structure is fine. 
However, need ability to defer scheduled tasks and logging.


**** DONE Parse the schedule properly into the interval structure
     CLOSED: [2017-08-19 Sat 17:53]
     :LOGBOOK:
     CLOCK: [2017-08-17 Thu 18:55]--[2017-08-17 Thu 19:20] =>  0:25
     CLOCK: [2017-08-17 Thu 18:25]--[2017-08-17 Thu 18:50] =>  0:25
     CLOCK: [2017-08-17 Thu 17:53]--[2017-08-17 Thu 18:20] =>  0:27
     :END:
Current state - schedule start_date parsing has been done. End_date, duration, repeat_interval remain. Data structure needs put into schema and then populated.

 
**** DONE Bugs parsing schedule time interval + repeat - is this done later?
     CLOSED: [2017-08-19 Sat 17:53]
**** DONE Bugs regeneration date format should be the same
     CLOSED: [2017-08-19 Sat 22:07]
**** DONE Parse or skip logbook 
     CLOSED: [2017-08-19 Sat 22:07]
      - probably a separate table. Same as tags. Did insert_all with ecto which may complicate this implementation
*** DONE Cleanup
    CLOSED: [2017-09-01 Fri 17:51]
**** DONE Refactor parse 
     CLOSED: [2017-09-01 Fri 17:23] SCHEDULED: <2017-08-24 Thu 18:00-20:00> DEADLINE: <2017-08-24 Thu 21:00>
     :LOGBOOK:
     CLOCK: [2017-08-24 Thu 17:30]--[2017-08-24 Thu 20:49] =>  3:19
     :END:
**** use ecto.multi or control the dual commit transaction
*** DONE POC - display UI for agenda
   :LOGBOOK:
   CLOCK: [2017-09-01 Fri 00:00]--[2017-09-01 Fri 23:59] => 23:59
   :END:
    CLOSED: [2017-09-01 Fri 10:17]
Not sure which is more important to do first. Capturing, offline support, notifications, logging activities. Notifications are fairly straightforward. Capture and offline support will need to come by building out a service worker for a progressive web app (pwa) . Looks like a lot more functionality will end up moving into the client. 

The server will contain the documents and the items stored in kinto db. 
The client will sync proxy auth through the server to make things consistent.
Client downloads entire documents and has all the data now.
  - capture
  - display the agenda
    - schedule / reschedule
    - mark as done
    - logging time / journal
    - import/export back to org-mode
  - most important tasks

  - https://www.realsimple.com/home-organizing/organizing/bullet-journal
  - http://help.bulletjournal.com/category/5-bullet-journaling-101
  - https://news.ycombinator.com/item?id=11856987
  - http://talk.dynalist.io/t/switching-to-dynalist-from-workflowy-and-todoist/475
  - memex - what did you do on what day
  - reminder to journal
**** PWA

Looks like an app-shell needs to be implemented and workboxjs seems to be the newest gold standard. 

Workflow:

Desires:
- communication over websocket
- little to no api if not required
- works offline

- Agenda shell
  - This is a rendered html page without data
  - Has some authorization info locally? 
  - Fetches from local to display immediately 
  - Fetches from remote to sync
    - update cache
    - and then redisplay on update

https://elixirforum.com/t/tips-for-building-resilient-frontend-apps-which-use-phoenix-channels-for-backend-communication/6216/15
https://www.viget.com/articles/phoenix-and-react-a-killer-combo
https://unpoly.com/
https://github.com/hyperapp/hyperapp


https://developers.google.com/web/fundamentals/instant-and-offline/offline-cookbook/

https://hnpwa.com/

https://github.com/Kinto/kinto/wiki/Brainstorm-rationale

Should probably take a PWA style working model and modify it:
https://github.com/SimonDEvans/notes

https://serviceworke.rs/
https://workboxjs.org/
https://nolanlawson.github.io/fronteers-2016/#/51
https://github.com/turbolinks/turbolinks
https://github.com/GoogleChrome/workbox
https://github.com/GoogleChrome/voice-memos
https://github.com/jakearchibald/trained-to-thrill/

**** Drab
Spent a few hours off and on investigating Drab. Server-side dom modifications is nice, but not sure how to deal with offline. Will have to build custom sync mechanism. 
**** Clojurescript
Want to use. Community is small compared to others though.

We'd have to make the externs for kinto. 
https://github.com/cljsjs

However, before doing anything with clojurescript get something working with javascript.
https://github.com/andreloureiro/andrel.me/blob/master/_posts/2016-01-09-a-basic-service-worker-implementation.md

Figwheel is pretty awesome. 

https://github.com/gadfly361/cljs-todomvc
https://github.com/tel/oak 

**** Kinto
     :LOGBOOK:
     CLOCK: [2017-08-30 Wed 19:00]--[2017-08-30 Wed 23:48] =>  4:48
     :END:

Kinto philosophy and architecture fits better. 

Comparison with Pouchdb and others:
http://www.servicedenuages.fr/en/generic-storage-ecosystem#storage-specs
http://docs.kinto-storage.org/en/stable/faq.html#comparison

Only other choice for offline storage was pouchdb, however, the cons are:
  - This will then require a db per user and the sharing of objects isn't possible easily anymore.
  - The permissioning requires a gateway from cloudant or etc. and going down that rabbithole. 

Close to the same data schema is possible with documents moving to a "collection" and all the objects into the "records". Groups, permissions, sharing out of the box. Possible performance issues on large datasets, but very unlikely. Fairly robust permissions for grouping:
http://docs.kinto-storage.org/en/stable/tutorials/permission-setups.html

***** Kinto setup 
Using docker image:
#!/bin/sh
docker run --rm --name  kinto --env-file ./kinto.env -p 8888:8888 kinto/kinto-server

$ cat kinto.env 
KINTO_STORAGE_BACKEND=kinto.core.storage.postgresql
KINTO_STORAGE_URL=postgres://postgres:postgres@10.0.2.99/kinto
MULTIAUTH_POLICIES=basicauth
KINTO_EXPERIMENTAL_PERMISSIONS_ENDPOINT=true
KINTO_PERMISSION_BACKEND=kinto.core.permission.postgresql
KINTO_PERMISSION_URL=postgres://postgres:postgres@10.0.2.99/kinto

***** Kinto schema - export doc 
Trying to generate a document will have the multi-commit issue as before:

#+BEGIN_SRC shell :results output
echo '{"data": {"description": "emacs", "status": "TODO", "title": "emacs", "content": "some crazy content 2", "level": 2, "priority": null, "state": "", "properties": [], "completed": false }}' | http POST http://localhost:8888/v1/buckets/default/collections/newdoc/records --auth user1:pass1

#+END_SRC

#+RESULTS:
: {"permissions":{"write":["basicauth:582ff7049eb3712f30dda114970902e93d64bf4ae3bd50373799d52ddd3e1dca"]},"data":{"id":"217b5227-50b9-44a0-9dcb-171383a5bb52","completed":false,"title":"emacs","level":2,"priority":null,"status":"TODO","state":"","content":"some crazy content 2","description":"emacs","properties":[],"last_modified":1504300871026}}

#+BEGIN_SRC shell :results output
echo '{"data": {"description": "emacs", "status": "TODO", "title": "emacs", "content": "some crazy content 2", "level": 2, "priority": null, "state": "", "properties": [], "completed": false }}' | 
    http POST http://localhost:8888/v1/buckets/default/collections/tasks/records --auth user2:pass2
#+END_SRC

#+RESULTS:
: {"permissions":{"write":["basicauth:344805ac2a747906f79c7b1246cc1a5f15c1ebaffed6ca0bba111c3ec9defebf"]},"data":{"id":"c9cdc6e4-71a9-4756-85b1-365c2688526f","completed":false,"title":"emacs","level":2,"priority":null,"status":"TODO","state":"","content":"some crazy content 2","description":"emacs","properties":[],"last_modified":1504299805753}}

#+BEGIN_SRC shell :results output
    #http GET http://localhost:8888/v1/buckets/default/collections/tasks --auth user3:pass3
    http GET http://localhost:8888/v1/buckets/default/collections --auth user1:pass1
#+END_SRC

#+RESULTS:
: {"data":[{"id":"newdoc","last_modified":1504300871014},{"id":"tasks","order":["7ca72a3e-afe7-452e-a2ba-2dfa02a3d01c","0d37d5f1-4d44-443b-a546-52c6e15d8f0c"],"last_modified":1504135779282}]}

#+BEGIN_SRC shell :results output
    http GET http://localhost:8888/v1/buckets/default/collections/tasks/records --auth user1:pass1
#+END_SRC

#+RESULTS:
: {"data":[{"id":"981f166f-f033-4826-93eb-b5c3dc385815","title":"emacs","priority":null,"level":2,"status":"TODO","description":"emacs","state":"","properties":[],"content":"some crazy content 2","last_modified":1504138324556},{"id":"4e9dc027-45d1-4c48-8fe7-54d0af328d68","title":"emacs","priority":null,"level":1,"status":"TODO","description":"emacs","state":"","properties":[],"content":"some crazy content","last_modified":1504138145187},{"id":"53f9cdd5-fcd3-4699-924b-4d68067b25df","last_modified":1504138066386},{"id":"afea9854-508b-42a5-b490-0c23eed2d42b","level":1,"status":"todo","description":"user1 data try4","last_updated":"2017-08-30T08:30:00","last_modified":1504138038761},{"id":"9b6d746d-2e92-444c-93cb-56ebf28354d2","last_modified":1504138024204},{"id":"8bad1995-1585-422d-a712-eb7bc8a011b7","level":1,"status":"todo","description":"user1 data try3","last_updated":"2017-08-30T08:30:00","last_modified":1504137990660},{"id":"0348491e-a1dc-4470-9f0a-97bd6d17f338","last_modified":1504137897503},{"id":"aa867294-471b-4f78-bc1a-d5de45c3716e","last_modified":1504137845531},{"id":"a8e4c8fa-6315-4a56-b52e-39363bc1eba9","last_modified":1504137742919},{"id":"7e21c027-e2e3-4e09-806c-8846f9635a60","last_modified":1504137734302},{"id":"a11c5585-36f4-438e-979a-4b96111c81ff","last_modified":1504137676441},{"id":"0d37d5f1-4d44-443b-a546-52c6e15d8f0c","level":1,"status":"todo","description":"user1 data try2","last_updated":"2017-08-30T08:30:00","last_modified":1504135413068},{"id":"7ca72a3e-afe7-452e-a2ba-2dfa02a3d01c","level":1,"status":"todo","description":"user1 data","last_updated":"2017-08-30T08:30:00","last_modified":1504131793546}]}

#+BEGIN_SRC shell :results output
#    http GET http://localhost:8888/v1/buckets --auth user3:pass3 # 6f0b5857-7aaa-da44-f0bb-648c6619f5f1 is the bucket for user3:pass3
#    http GET http://localhost:8888/v1/buckets --auth user2:pass2 #  f1abf618-c58c-1496-5274-b7e8be8a259b is the bucket for user3:pass3
#     echo '{"permissions": {"read": ["basicauth:7fc2f542fc5a66bcbcb45bea54ec43c5db5020a03286ebb84dbb120ef66b2a39"]}}' | http PATCH http://localhost:8888/v1/buckets/default/collections/tasks/records/90dbf30d-1d5e-4874-8878-8ffcc67e8ffb -v --auth 'user2:pass2' # grant perms from user2 to user3 for record
  
    #http GET http://localhost:8888/v1/buckets/default/collections/tasks/records --auth user2:pass2
   # http GET http://localhost:8888/v1/buckets/default/collections/tasks/records --auth user3:pass3
#+END_SRC

#+RESULTS:
: {"data":[{"id":"683ea5c7-645b-4236-9f2f-48ec3b1542d9","completed":false,"title":"new item","last_modified":1504297795367},{"id":"8ad85f69-5056-47dc-9fdb-6fb473fc67e3","completed":false,"title":"New again","last_modified":1504286396202},{"id":"09c5b364-f358-41ff-b7f3-2fcb9470511a","completed":false,"title":"what","last_modified":1504273413555}]}

It worked, the perms table has:
 /buckets/6f0b5857-7aaa-da44-f0bb-648c6619f5f1                                                                | write      | basicauth:7fc2f542fc5a66bcbcb45bea54ec43c5db5020a03286ebb84dbb120ef66b2a39
 /buckets/6f0b5857-7aaa-da44-f0bb-648c6619f5f1/collections/tasks                                              | write      | basicauth:7fc2f542fc5a66bcbcb45bea54ec43c5db5020a03286ebb84dbb120ef66b2a39
 /buckets/6f0b5857-7aaa-da44-f0bb-648c6619f5f1/collections/tasks/records/09c5b364-f358-41ff-b7f3-2fcb9470511a | write      | basicauth:7fc2f542fc5a66bcbcb45bea54ec43c5db5020a03286ebb84dbb120ef66b2a39
 /buckets/6f0b5857-7aaa-da44-f0bb-648c6619f5f1/collections/tasks/records/8ad85f69-5056-47dc-9fdb-6fb473fc67e3 | write      | basicauth:7fc2f542fc5a66bcbcb45bea54ec43c5db5020a03286ebb84dbb120ef66b2a39
 /buckets/6f0b5857-7aaa-da44-f0bb-648c6619f5f1/collections/tasks/records/683ea5c7-645b-4236-9f2f-48ec3b1542d9 | write      | basicauth:7fc2f542fc5a66bcbcb45bea54ec43c5db5020a03286ebb84dbb120ef66b2a39
 /buckets/f1abf618-c58c-1496-5274-b7e8be8a259b/collections/tasks/records/90dbf30d-1d5e-4874-8878-8ffcc67e8ffb | read       | basicauth:7fc2f542fc5a66bcbcb45bea54ec43c5db5020a03286ebb84dbb120ef66b2a39

#+BEGIN_SRC shell :results output
#    http GET http://localhost:8888/v1/buckets/default/collections/tasks/records --auth user3:pass3
    http GET http://localhost:8888/v1/buckets/f1abf618-c58c-1496-5274-b7e8be8a259b/collections/tasks/records --auth user3:pass3
#+END_SRC

#+RESULTS:
: {"data":[{"id":"c9cdc6e4-71a9-4756-85b1-365c2688526f","completed":false,"title":"emacs","priority":null,"level":2,"status":"TODO","description":"emacs","state":"","properties":[],"content":"some crazy content 2","last_modified":1504299805753},{"id":"90dbf30d-1d5e-4874-8878-8ffcc67e8ffb","level":1,"status":"todo","description":"test1","last_updated":"2017-08-30T08:30:00","last_modified":1504298161138}]}

Trying to set perms on the collection tasks
#+BEGIN_SRC shell :results output
     echo '{"permissions": {"read": ["basicauth:7fc2f542fc5a66bcbcb45bea54ec43c5db5020a03286ebb84dbb120ef66b2a39"]}}' | http PATCH http://localhost:8888/v1/buckets/default/collections/tasks -v --auth 'user2:pass2' # grant perms from user2 to user3 for collection
  
    #http GET http://localhost:8888/v1/buckets/default/collections/tasks/records --auth user2:pass2
   # http GET http://localhost:8888/v1/buckets/default/collections/tasks/records --auth user3:pass3
#+END_SRC

#+RESULTS:
#+begin_example
PATCH /v1/buckets/default/collections/tasks HTTP/1.1
Content-Length: 106
Accept-Encoding: gzip, deflate
Host: localhost:8888
Accept: application/json
User-Agent: HTTPie/0.9.2
Connection: keep-alive
Content-Type: application/json
Authorization: Basic dXNlcjI6cGFzczI=

{"permissions": {"read": ["basicauth:7fc2f542fc5a66bcbcb45bea54ec43c5db5020a03286ebb84dbb120ef66b2a39"]}}


HTTP/1.1 200 OK
Access-Control-Expose-Headers: Retry-After, Alert, Backoff, Content-Length
Content-Length: 242
Content-Type: application/json
Date: Fri, 01 Sep 2017 21:05:06 GMT
Etag: "1504299906940"
Last-Modified: Fri, 01 Sep 2017 21:05:06 GMT
Server: waitress
X-Content-Type-Options: nosniff

{"permissions":{"write":["basicauth:344805ac2a747906f79c7b1246cc1a5f15c1ebaffed6ca0bba111c3ec9defebf"],"read":["basicauth:7fc2f542fc5a66bcbcb45bea54ec43c5db5020a03286ebb84dbb120ef66b2a39"]},"data":{"id":"tasks","last_modified":1504299906940}}
#+end_example

***** Kinto schema - How to generate the agendas
http://docs.kinto-storage.org/en/stable/api/1.x/filtering.html

#+BEGIN_SRC shell :results output
    http GET "http://localhost:8888/v1/buckets/default/collections/tasks/records?gt_level=1&status=TODO" --auth user1:pass1
#+END_SRC

#+RESULTS:
: {"data":[{"status":"TODO","state":"","id":"981f166f-f033-4826-93eb-b5c3dc385815","priority":null,"properties":[],"description":"emacs","level":2,"title":"emacs","content":"some crazy content 2","last_modified":1504138324556}]}

***** Kinto permissions
Synchronization happens at a bucket level. Each user has a default bucket which they sync automatically. Everything after that for 
  - tasks = new Kinto(remotedb).collection("tasks"), tasks.sync(syncOptions)
Separately need to fetch from different buckets. 

Operates on the bucket + records level . 
Can set sharing permission at the bucket, collection, or record level. Fetching anything of interest, however, is a completely different problem.

**** Todo app examples with Kinto
file:///home/tjheeta/repos/self/all-todo-test/kinto.js/demo/index.html
https://github.com/Kinto/kinto/wiki/App-examples
http://leplatrem.github.io/kinto-demo-calendar/#public
https://github.com/leplatrem/kinto-demo-calendar/
https://github.com/leplatrem/Routina

**** Frontend thoughts 
JS frontend is insane.

https://github.com/facebook/react  
https://github.com/developit/preact
https://github.com/angular/angular - 27000 - Too complicated.
https://github.com/meteor/meteor
https://github.com/emberjs/ember.js/
https://github.com/apollographql/apollo-client
https://github.com/vuejs/vue
https://github.com/MithrilJS/mithril.js - 
https://github.com/knockout/knockout - 8400 - MVVM
https://github.com/sveltejs/svelte - 5100 - compile time
https://github.com/turbolinks/turbolinks - 4000
https://github.com/unpoly/unpoly - 139
https://github.com/Polymer/polymer - 18000 - No idea what web components are.
https://github.com/zeit/next.js/ - 16700 - Server rendered react? Already have backend.
https://cycle.js.org/ - 


**** DONE Learning hyperapp to build a PWA/SPA
     CLOSED: [2017-09-01 Fri 10:16]
https://github.com/ramda/ramda - hyperapp probably needs something like this
https://github.com/lodash/lodash - or this
https://github.com/hyperapp/hyperapp/issues/244#issuecomment-321145114
https://github.com/hyperapp/hyperapp/blob/master/docs/vdom-events.md - adapting an external library
https://github.com/hyperapp/hyperapp/issues/251 - testing
***** DONE Need to figure out how to route to the next page - almost done
      CLOSED: [2017-08-31 Thu 01:11]
***** DONE Try to add kinto - mixin necessary?
      CLOSED: [2017-08-31 Thu 23:37]
** MVP2
*** DONE Thoughts
    CLOSED: [2017-09-01 Fri 17:47]
Need to clearly dilineate what happens server-side vs client-side. If items are being collaborated on, could open a websocket and make a lock for it. 
Comments - are they a separate system or do we write into the same schema?
Offline - editing is based on whether they are personal documents or not. Need a lock for shared. If go offline, warn that may have to merge conflicts or save duplicate version, but can continue editing.
Binpacking - does the client do it or the server?
If a person is involved in 50 objects, some public, delegated, some private. 
How do comments work? Client can connect to the backend system for comments, but what is real-time, and what is cached?  

Kinto requires bucket + collection level for anything. Specific buckets for fetching. In fact, if a document is a collection, then already have problems creating an agenda. Need to fetch all records in multiple collections, store them, build an agenda.  
- Sync multiple collections. That sucks.
- Make a document a record. Then will have to parse and create the agenda each time. That sucks.
- Have tasks be replicated into an inbox bucket for a user. This doesn't really work except for maybe 2-way.  
- Build a custom offline cache and replication. Need to replicate everything that a user has access to, not just by bucket or collection. That sucks.
- Instead of each document being a collection, have a document collection and an object collection. Get a full list of objects to build an agenda. Ignore anything about a document. When sharing, can move the object into a shared bucket location and can still have reference to it? No, will have build problem again. 
- A dedicated group for collaboration with org-mode could have a bucket with group perms. After that, each can take objects offline, work, change state, etc.
- Move permissions directly onto the object itself.
- All objects for all users are in a single collection (could be sharded).
- Team-org-mode. Team/group has a bucket with two collections called documents and objects. Have a personal bucket. For each bucket, dosync. Personal bucket has agenda - which has metadata about the real object - title + location. Actually, can just build the agenda off of this without the sync. An object needs an "assigned" field also.
- Product usage. No one is going to partially share a document. The atomic unit for collaboration is the document, not the object. If anything, an object and children should be able to be moved to another document, with a reference back if necessary. Kinto does sharding by buckets => can represent a group. No one would share a subtree and get comments.
- Are comments objects? For instance, a collection of these objects can also represent a forum thread. A comment could be represented by a headline. Could put comments into their own collection? Maybe want to turn comments into objects. 

  
*** Conclusion
1) Single user productivity 
   - agenda
   - notifications
   - capture
   - dumb server, smart client, bin-packing, etc. done in js
2) Collaboration -  Kinto can go pretty far with team/personal buckets with collections of doc + objects.
   - Each group is represented by a bucket. Can be sharded. 
   - Can build agenda - need to resolve over all buckets.
   - Can share documents / move documents / create documents from object subtrees if necessary.
   - Locking for editing documents online via websocket
   - Can shared and assign tasks by fetch from multiple buckets/collections.
   - External contributors also work by adding to a single group. All hierarchy needs to be done via bucket-id or secondary table.
   - Moving groups from public to private - offline stuff would still exist, but could remove keys from keychain?
   - Syncing multiple buckets for sharing allows interesting E2E encryption possibilities.
   - Search - do we do it in the browser if everything is encrypted - depends on transform on sync + indexeddb performance

Will be multiple calls to fetch unless we overlay our own queries into the database or maybe write a plugin.
  - https://github.com/Kinto/kinto-changes
This, however, won't help with changes. 
   
*** Get real data - Elixir to Kinto
What about logbook?
Need to revamp the schema. 
Each document in document collection
Each object is now a record in objects collection. 
Personal buckets are auto-synced.
*** Notifications
*** Pre and post syncing data immediately / retries / backoffs
*** Authorization
**** Kinto proxying
*** Display agenda
**** UI Display
**** Onclick and onslide events
*** Pick and schedule things onto agenda
*** Add REST API for sync back to emacs
**** User security
**** Compare the objects 
      - Need to modify the object from ui/db and then test uploads
**** Add REST api?
      Start off with a simple curl client to do whole files
      Later can make an object level api and make an elisp client - update versions / conflict resolution
*** Capture to different documents
*** Need to namespace buckets based on org/groupname/id? :ms.shared:

*** Offline test
*** Bin-packing
*** User settings
*** Daily review
*** Weekly review
*** Conflict resolution?
*** Connect to phoenix channels - why? Comments/feedback?
*** Server-side rendering
*** Add full calendar?
*** Check for updates of code versions and update notice
*** Components
https://github.com/hyperapp/hyperapp/issues/238#issuecomment-310999839
*** How to include different files
*** capture
****** bookmarklets directly to server 
****** pictures and attachments
 
- 
*** CRDT editing :ms.shared:
- https://github.com/xwiki-contrib/chainpad
- https://hal.archives-ouvertes.fr/inria-00336191/
- https://news.ycombinator.com/item?id=12303100
- https://pages.lip6.fr/Marek.Zawirski/papers/SwiftCloud-RR-8347.pdf
*** Inbox - integration point for externs and updates?
*** Security - Moving groups from public to private - offline stuff would still exist. 

*** Need to be able to take an object and move it to another document and leave a reference if necessary. On import/export, need to be able to self-refer to these documents locally. :ms.shared:
*** Encryption per bucket 
Need to have a master password. Each user has a keychain for all accessible buckets. The buckets get synced locally, decrypted as necessary, and stuff built. Re-keying will be massively painful. 
*** Import/Export Bugs
**** DONE scheduled_date_range, scheduled_time_interval not written to db
     CLOSED: [2017-08-19 Sat 22:43]
**** Regenerate org-file - scheduled date - the second date of the range is missing
[[file:~/repos/self/ttl/lib/ttl/parse/export.ex::defp%20db_date_to_string(date,%20bracket,%20time_interval,%20date_range,%20repeat_interval%20)%20do][fix it here]]
**** Still need to parse tags into database
**** More complete tests for generate -> regenerate with UUID's
*** Security
https://turtlapp.com/
https://standardnotes.org/blog/7/announcing-our-2017-security-audit-results
https://github.com/standardfile
*** parse additional properties for scheduling + contexts + tags
*** notifications
*** capture
- some sort of ifttt integration? send email to an interface and it will go into todo?
*** UI Tests
https://github.com/webpro/Automated-SPA-Testing
*** Cleanup - add spec to all functions
*** Import/export Tests
       Updates
       - An old object (all db counts same)
       - A new object gets added (db count + 1)
       - the new object gets modified (db count same)

* Scratch

#+BEGIN_SRC elixir :results output
2 + 2
#+END_SRC

* clocktable
#+BEGIN: clocktable :maxlevel 5 :scope file
#+CAPTION: Clock summary at [2017-09-01 Fri 17:52]
| Headline                                         | Time       |          |         |       |      |
|--------------------------------------------------+------------+----------+---------+-------+------|
| *Total time*                                     | *2d 12:56* |          |         |       |      |
|--------------------------------------------------+------------+----------+---------+-------+------|
| Ttl                                              | 2d 12:56   |          |         |       |      |
| \_  MVP1                                         |            | 2d 12:56 |         |       |      |
| \_    import/export to api.                      |            |          | 1d 4:50 |       |      |
| \_      consolidate sections                     |            |          |         |  2:07 |      |
| \_      Need to fix the planning parser to...    |            |          |         |  0:25 |      |
| \_      implement db schema                      |            |          |         |  1:15 |      |
| \_      write to database                        |            |          |         | 11:06 |      |
| \_        Make it into a function                |            |          |         |       | 0:30 |
| \_        Make a solid decision on what to do... |            |          |         |       | 1:03 |
| \_        Parse and cast the dates               |            |          |         |       | 4:58 |
| \_      Need to parse the file metadata          |            |          |         |  1:35 |      |
| \_      regenerate file from database - with...  |            |          |         |  4:59 |      |
| \_      Properties - parse, store, and write     |            |          |         |  1:47 |      |
| \_      Add version and id into regenerated...   |            |          |         |  0:24 |      |
| \_      Read file uuid from file to pull objects |            |          |         |  2:07 |      |
| \_      Start of file exception                  |            |          |         |  0:25 |      |
| \_      Ensure data gets updated on change       |            |          |         |  0:08 |      |
| \_      make an interval data structure for...   |            |          |         |  1:15 |      |
| \_      Parse the schedule properly into the...  |            |          |         |  1:17 |      |
| \_    Cleanup                                    |            |          | 3:19    |       |      |
| \_      Refactor parse                           |            |          |         |  3:19 |      |
| \_    POC - display UI for agenda                |            |          | 1d 4:47 |       |      |
| \_      Kinto                                    |            |          |         |  4:48 |      |
#+END:
